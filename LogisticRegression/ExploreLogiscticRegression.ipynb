{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'review', 'rating']\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "import helpers\n",
    "\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    return text.translate(None, string.punctuation)\n",
    "\n",
    "# get the data\n",
    "products = pd.read_csv(\"amazon_baby.csv\")\n",
    "print list(products)\n",
    "print type(products)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'review', 'rating', 'review_clean']\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# clean the data\n",
    "products = products.fillna({'review':''})\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)\n",
    "print list(products)\n",
    "# ignore all rating 3s since they tend to be neutral\n",
    "products = products[products['rating'] != 3]\n",
    "print type(products)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'review', 'rating', 'review_clean', 'sentiment']\n"
     ]
    }
   ],
   "source": [
    "# extract sentiment positive: rating >=4, negative: rating <= 2\n",
    "products['sentiment'] = products['rating'].apply(lambda rating: + 1 if rating > 3 else -1)\n",
    "print list(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33336\n"
     ]
    }
   ],
   "source": [
    "# split into test data and training data randomly\n",
    "# to get the same results at the test use json indexes\n",
    "with open('module-2-assignment-test-idx.json') as data_file:\n",
    "    test_idx = json.load(data_file)\n",
    "test_data = products.iloc[test_idx].copy()\n",
    "print len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133416\n"
     ]
    }
   ],
   "source": [
    "with open('module-2-assignment-train-idx.json') as data_file:\n",
    "    train_idx = json.load(data_file)\n",
    "train_data = products.iloc[train_idx].copy()\n",
    "print len(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='\\\\b\\\\w+\\\\b', tokenizer=None,\n",
      "        vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "# compute word count in each review: bag of words\n",
    "# use sparse matrix to store the collection of word count vectors\n",
    "# because some words occur only in some reviews\n",
    "\n",
    "# 1. Learn a vocabulary of all words in all reviews in the training data. Each word is a column\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b') #single word pattern\n",
    "print vectorizer\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_clean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. Convert the test data into a sparse matrix, using the same word-column mapping\n",
    "test_matrix = vectorizer.transform(test_data['review_clean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 87458)\t1\n",
      "  (0, 52346)\t1\n",
      "  (0, 60973)\t1\n",
      "  (0, 35380)\t1\n",
      "  (0, 67820)\t1\n",
      "  (0, 119315)\t1\n",
      "  (0, 75845)\t1\n",
      "  (0, 59309)\t1\n",
      "  (0, 52830)\t1\n",
      "  (0, 119288)\t1\n",
      "  (0, 69878)\t2\n",
      "  (0, 72811)\t1\n",
      "  (0, 14624)\t1\n",
      "  (0, 119389)\t1\n",
      "  (0, 80500)\t1\n",
      "  (0, 63567)\t1\n",
      "  (0, 54276)\t1\n",
      "  (0, 34453)\t1\n",
      "  (0, 72510)\t2\n",
      "  (0, 116798)\t1\n",
      "  (0, 10505)\t3\n",
      "  (0, 37328)\t1\n",
      "  (0, 21721)\t1\n",
      "  (0, 57486)\t3\n",
      "  (1, 85937)\t1\n",
      "  :\t:\n",
      "  (133415, 45698)\t1\n",
      "  (133415, 119439)\t3\n",
      "  (133415, 117337)\t1\n",
      "  (133415, 37640)\t2\n",
      "  (133415, 10440)\t1\n",
      "  (133415, 54987)\t1\n",
      "  (133415, 62056)\t2\n",
      "  (133415, 45067)\t2\n",
      "  (133415, 51051)\t3\n",
      "  (133415, 83729)\t2\n",
      "  (133415, 7280)\t7\n",
      "  (133415, 57196)\t4\n",
      "  (133415, 107483)\t2\n",
      "  (133415, 44646)\t4\n",
      "  (133415, 63165)\t1\n",
      "  (133415, 108946)\t5\n",
      "  (133415, 96190)\t1\n",
      "  (133415, 106249)\t10\n",
      "  (133415, 115480)\t3\n",
      "  (133415, 87458)\t1\n",
      "  (133415, 69878)\t3\n",
      "  (133415, 54276)\t9\n",
      "  (133415, 72510)\t1\n",
      "  (133415, 10505)\t5\n",
      "  (133415, 57486)\t1\n",
      "  (0, 5842)\t1\n",
      "  (0, 7280)\t1\n",
      "  (0, 9530)\t1\n",
      "  (0, 10440)\t1\n",
      "  (0, 10803)\t1\n",
      "  (0, 12630)\t1\n",
      "  (0, 13597)\t2\n",
      "  (0, 15930)\t1\n",
      "  (0, 16154)\t2\n",
      "  (0, 29211)\t1\n",
      "  (0, 37640)\t1\n",
      "  (0, 39997)\t1\n",
      "  (0, 44646)\t1\n",
      "  (0, 50567)\t1\n",
      "  (0, 50938)\t1\n",
      "  (0, 51051)\t1\n",
      "  (0, 52346)\t1\n",
      "  (0, 53021)\t1\n",
      "  (0, 53116)\t1\n",
      "  (0, 54276)\t1\n",
      "  (0, 54574)\t1\n",
      "  (0, 54987)\t1\n",
      "  (0, 55712)\t1\n",
      "  (0, 57196)\t2\n",
      "  (0, 57279)\t1\n",
      "  :\t:\n",
      "  (33335, 40980)\t1\n",
      "  (33335, 45698)\t1\n",
      "  (33335, 51051)\t1\n",
      "  (33335, 54276)\t2\n",
      "  (33335, 57486)\t1\n",
      "  (33335, 59262)\t1\n",
      "  (33335, 63567)\t1\n",
      "  (33335, 64896)\t1\n",
      "  (33335, 65639)\t1\n",
      "  (33335, 69694)\t1\n",
      "  (33335, 70987)\t1\n",
      "  (33335, 73618)\t1\n",
      "  (33335, 83729)\t1\n",
      "  (33335, 84439)\t1\n",
      "  (33335, 86879)\t1\n",
      "  (33335, 94215)\t1\n",
      "  (33335, 103337)\t1\n",
      "  (33335, 105638)\t1\n",
      "  (33335, 106249)\t2\n",
      "  (33335, 106938)\t1\n",
      "  (33335, 107092)\t1\n",
      "  (33335, 107483)\t1\n",
      "  (33335, 115480)\t1\n",
      "  (33335, 117906)\t1\n",
      "  (33335, 119932)\t1\n"
     ]
    }
   ],
   "source": [
    "print train_matrix\n",
    "print test_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training the model...\n",
      "finished training the model!\n"
     ]
    }
   ],
   "source": [
    "# Train a sentiment classifier with logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_regression = LogisticRegression() #call to get an instance of the linearRegression class\n",
    "print \"training the model...\"\n",
    "sentiment_model = logistic_regression.fit(train_matrix, train_data[\"sentiment\"])\n",
    "print \"finished training the model!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights > = 0 --->  85938\n",
      "weights < 0   --->  35774\n"
     ]
    }
   ],
   "source": [
    "# There should be over 100,000 coefficients in this sentiment_model.\n",
    "# Recall from the lecture that positive weights w_j correspond to weights that cause positive sentiment,\n",
    "# while negative weights correspond to negative sentiment.\n",
    "# Calculate the number of positive (>= 0, which is actually nonnegative) coefficients.\n",
    "# Quiz question: How many weights are >= 0?\n",
    "\n",
    "sentiment_model_nonnegative_weights = logistic_regression.coef_[logistic_regression.coef_ >= 0]\n",
    "sentiment_model_negative_weights = logistic_regression.coef_[logistic_regression.coef_ < 0]\n",
    "\n",
    "print \"weights > = 0 ---> \", len(sentiment_model_nonnegative_weights)\n",
    "print \"weights < 0   ---> \", len(sentiment_model_negative_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 name  \\\n",
      "59                          Our Baby Girl Memory Book   \n",
      "71  Wall Decor Removable Decal Sticker - Colorful ...   \n",
      "91  New Style Trailing Cherry Blossom Tree Decal R...   \n",
      "\n",
      "                                               review  rating  \\\n",
      "59  Absolutely love it and all of the Scripture in...       5   \n",
      "71  Would not purchase again or recommend. The dec...       2   \n",
      "91  Was so excited to get this product for my baby...       1   \n",
      "\n",
      "                                         review_clean  sentiment  \n",
      "59  Absolutely love it and all of the Scripture in...          1  \n",
      "71  Would not purchase again or recommend The deca...         -1  \n",
      "91  Was so excited to get this product for my baby...         -1  \n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Making predictions on the test data\n",
    "sample_test_data = test_data[10:13]\n",
    "print sample_test_data\n",
    "print len(sample_test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maybe positive\n",
      "Absolutely love it and all of the Scripture in it.  I purchased the Baby Boy version for my grandson when he was born and my daughter-in-law was thrilled to receive the same book again.\n",
      "maybe negative\n",
      "Would not purchase again or recommend. The decals were thick almost plastic like and were coming off the wall as I was applying them! The would NOT stick! Literally stayed stuck for about 5 minutes then started peeling off.\n",
      "also maybe negative\n",
      "Was so excited to get this product for my baby girls bedroom!  When I got it the back is NOT STICKY at all!  Every time I walked into the bedroom I was picking up pieces off of the floor!  Very very frustrating!  Ended up having to super glue it to the wall...very disappointing.  I wouldn't waste the time or money on it.\n"
     ]
    }
   ],
   "source": [
    "# digging deeper into test data\n",
    "\n",
    "type(sample_test_data)\n",
    "list(sample_test_data)\n",
    "\n",
    "print \"maybe positive\\n\", sample_test_data['review'].iloc[0]\n",
    "print \"maybe negative\\n\", sample_test_data['review'].iloc[1]\n",
    "print \"also maybe negative\\n\", sample_test_data['review'].iloc[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting sentiment...\n",
      "[  5.59843439  -3.15360099 -10.42482888]\n",
      "[ 1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "print \"predicting sentiment...\"\n",
    "# predictions for the sample test data\n",
    "sample_test_matrix = vectorizer.transform(sample_test_data[\"review_clean\"])\n",
    "sample_scores = sentiment_model.decision_function(sample_test_matrix)\n",
    "print sample_scores\n",
    "\n",
    "sample_sentiments = sentiment_model.predict(sample_test_matrix)\n",
    "print sample_sentiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996310008801\n",
      "0.0409496234075\n",
      "0.000030\n"
     ]
    }
   ],
   "source": [
    "# Using the scores calculated previously, write code to calculate the probability \n",
    "# that a sentiment is positive using the above formula. \n",
    "# For each row, the probabilities should be a number in the range [0, 1].\n",
    "\n",
    "def get_probability(score):\n",
    "    return 1/(1+np.exp(-score))\n",
    "\n",
    "print get_probability(sample_scores[0])\n",
    "print get_probability(sample_scores[1])\n",
    "print \"%.6f\" % get_probability(sample_scores[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9         0.779299\n",
      "10        0.999999\n",
      "16        0.933782\n",
      "20        0.999978\n",
      "28        0.979965\n",
      "36        0.999954\n",
      "37        0.998730\n",
      "41        0.801605\n",
      "43        0.998449\n",
      "56        0.997332\n",
      "59        0.996310\n",
      "71        0.040950\n",
      "91        0.000030\n",
      "112       0.995612\n",
      "115       0.992937\n",
      "116       0.976605\n",
      "120       0.992583\n",
      "123       0.939207\n",
      "129       0.039157\n",
      "135       0.998936\n",
      "140       0.998639\n",
      "146       0.999055\n",
      "149       1.000000\n",
      "157       0.999969\n",
      "158       0.999976\n",
      "160       0.979026\n",
      "164       0.975281\n",
      "171       0.952372\n",
      "177       1.000000\n",
      "180       0.999620\n",
      "            ...   \n",
      "183365    0.999047\n",
      "183370    1.000000\n",
      "183377    0.877573\n",
      "183388    0.997951\n",
      "183393    0.811225\n",
      "183397    0.996710\n",
      "183404    0.897002\n",
      "183405    1.000000\n",
      "183406    0.999929\n",
      "183414    0.479149\n",
      "183415    0.981972\n",
      "183418    0.868000\n",
      "183434    0.999901\n",
      "183436    0.999974\n",
      "183447    0.999999\n",
      "183456    0.998470\n",
      "183459    0.929161\n",
      "183460    1.000000\n",
      "183461    0.281355\n",
      "183465    1.000000\n",
      "183468    0.999984\n",
      "183473    0.999684\n",
      "183483    0.999941\n",
      "183487    0.990527\n",
      "183499    0.997831\n",
      "183507    0.975288\n",
      "183515    0.999072\n",
      "183522    0.999995\n",
      "183524    0.999997\n",
      "183530    0.981152\n",
      "Name: probabilities, Length: 33336, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Now examine the whole test data set\n",
    "# Using the sentiment_model, find the 20 reviews in the entire test_data with the highest probability \n",
    "# of being classified as a positive review. \n",
    "# We refer to these as the \"most positive reviews.\"\n",
    "\n",
    "scores = sentiment_model.decision_function(test_matrix)\n",
    "probabilities = np.vectorize(get_probability)\n",
    "\n",
    "# add a new column in the test_data with the calculated probabilities\n",
    "test_data.loc[:,'probabilities'] = probabilities(scores)\n",
    "print test_data['probabilities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83234</th>\n",
       "      <td>Thirsties Hemp Inserts 2 Pack, Small 6-18 Lbs</td>\n",
       "      <td>My Experience: Babykicks Inserts failure vs RA...</td>\n",
       "      <td>5</td>\n",
       "      <td>My Experience Babykicks Inserts failure vs RAV...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.656314e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31741</th>\n",
       "      <td>Regalo My Cot Portable Bed, Royal Blue</td>\n",
       "      <td>If I could give this product zero stars I woul...</td>\n",
       "      <td>1</td>\n",
       "      <td>If I could give this product zero stars I woul...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.637796e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>Safety 1st Deluxe 4-in-1 Bath Station</td>\n",
       "      <td>This item is junk.  I originally chose it beca...</td>\n",
       "      <td>1</td>\n",
       "      <td>This item is junk  I originally chose it becau...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.083568e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154878</th>\n",
       "      <td>VTech Communications Safe &amp;amp; Sound Digital ...</td>\n",
       "      <td>First, the distance on these are no more than ...</td>\n",
       "      <td>1</td>\n",
       "      <td>First the distance on these are no more than 7...</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.092509e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149987</th>\n",
       "      <td>NUK Cook-n-Blend Baby Food Maker</td>\n",
       "      <td>It thought this would be great. I did a lot of...</td>\n",
       "      <td>1</td>\n",
       "      <td>It thought this would be great I did a lot of ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>7.424565e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75994</th>\n",
       "      <td>Peg-Perego Tatamia High Chair, White Latte</td>\n",
       "      <td>I can see why there are so many good reviews o...</td>\n",
       "      <td>2</td>\n",
       "      <td>I can see why there are so many good reviews o...</td>\n",
       "      <td>-1</td>\n",
       "      <td>7.216031e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40079</th>\n",
       "      <td>Chicco Cortina KeyFit 30 Travel System in Adve...</td>\n",
       "      <td>My wife and I have used this system in two car...</td>\n",
       "      <td>1</td>\n",
       "      <td>My wife and I have used this system in two car...</td>\n",
       "      <td>-1</td>\n",
       "      <td>6.570205e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172090</th>\n",
       "      <td>Belkin WeMo Wi-Fi Baby Monitor for Apple iPhon...</td>\n",
       "      <td>I read so many reviews saying the Belkin WiFi ...</td>\n",
       "      <td>2</td>\n",
       "      <td>I read so many reviews saying the Belkin WiFi ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>6.523675e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59546</th>\n",
       "      <td>Ellaroo Mei Tai Baby Carrier - Hershey</td>\n",
       "      <td>This is basically an overpriced piece of fabri...</td>\n",
       "      <td>1</td>\n",
       "      <td>This is basically an overpriced piece of fabri...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4.646360e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9915</th>\n",
       "      <td>Cosco Alpha Omega Elite Convertible Car Seat</td>\n",
       "      <td>I bought this car seat after both seeing  the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>I bought this car seat after both seeing  the ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4.132717e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113995</th>\n",
       "      <td>Motorola Digital Video Baby Monitor with Room ...</td>\n",
       "      <td>DO NOT BUY THIS BABY MONITOR!I purchased this ...</td>\n",
       "      <td>1</td>\n",
       "      <td>DO NOT BUY THIS BABY MONITORI purchased this m...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.035454e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10677</th>\n",
       "      <td>Philips AVENT Newborn Starter Set</td>\n",
       "      <td>It's 3am in the morning and needless to say, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Its 3am in the morning and needless to say thi...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.031014e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81332</th>\n",
       "      <td>Cloth Diaper Sprayer--styles may vary</td>\n",
       "      <td>I bought this sprayer out of desperation durin...</td>\n",
       "      <td>1</td>\n",
       "      <td>I bought this sprayer out of desperation durin...</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.967167e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53207</th>\n",
       "      <td>Safety 1st High-Def Digital Monitor</td>\n",
       "      <td>We bought this baby monitor to replace a diffe...</td>\n",
       "      <td>1</td>\n",
       "      <td>We bought this baby monitor to replace a diffe...</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.200936e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94560</th>\n",
       "      <td>The First Years True Choice P400 Premium Digit...</td>\n",
       "      <td>Note: we never installed batteries in these un...</td>\n",
       "      <td>1</td>\n",
       "      <td>Note we never installed batteries in these uni...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4.652177e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155287</th>\n",
       "      <td>VTech Communications Safe &amp;amp; Sounds Full Co...</td>\n",
       "      <td>This is my second video monitoring system, the...</td>\n",
       "      <td>1</td>\n",
       "      <td>This is my second video monitoring system the ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.758666e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48694</th>\n",
       "      <td>Adiri BPA Free Natural Nurser Ultimate Bottle ...</td>\n",
       "      <td>I will try to write an objective review of the...</td>\n",
       "      <td>2</td>\n",
       "      <td>I will try to write an objective review of the...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.245939e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77072</th>\n",
       "      <td>Safety 1st Exchangeable Tip 3 in 1 Thermometer</td>\n",
       "      <td>I thought it sounded great to have different t...</td>\n",
       "      <td>1</td>\n",
       "      <td>I thought it sounded great to have different t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>8.168697e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120209</th>\n",
       "      <td>Levana Safe N'See Digital Video Baby Monitor w...</td>\n",
       "      <td>This is the first review I have ever written o...</td>\n",
       "      <td>1</td>\n",
       "      <td>This is the first review I have ever written o...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.845151e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16042</th>\n",
       "      <td>Fisher-Price Ocean Wonders Aquarium Bouncer</td>\n",
       "      <td>We have not had ANY luck with Fisher-Price pro...</td>\n",
       "      <td>2</td>\n",
       "      <td>We have not had ANY luck with FisherPrice prod...</td>\n",
       "      <td>-1</td>\n",
       "      <td>8.768872e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "83234       Thirsties Hemp Inserts 2 Pack, Small 6-18 Lbs   \n",
       "31741              Regalo My Cot Portable Bed, Royal Blue   \n",
       "1116                Safety 1st Deluxe 4-in-1 Bath Station   \n",
       "154878  VTech Communications Safe &amp; Sound Digital ...   \n",
       "149987                   NUK Cook-n-Blend Baby Food Maker   \n",
       "75994          Peg-Perego Tatamia High Chair, White Latte   \n",
       "40079   Chicco Cortina KeyFit 30 Travel System in Adve...   \n",
       "172090  Belkin WeMo Wi-Fi Baby Monitor for Apple iPhon...   \n",
       "59546              Ellaroo Mei Tai Baby Carrier - Hershey   \n",
       "9915         Cosco Alpha Omega Elite Convertible Car Seat   \n",
       "113995  Motorola Digital Video Baby Monitor with Room ...   \n",
       "10677                   Philips AVENT Newborn Starter Set   \n",
       "81332               Cloth Diaper Sprayer--styles may vary   \n",
       "53207                 Safety 1st High-Def Digital Monitor   \n",
       "94560   The First Years True Choice P400 Premium Digit...   \n",
       "155287  VTech Communications Safe &amp; Sounds Full Co...   \n",
       "48694   Adiri BPA Free Natural Nurser Ultimate Bottle ...   \n",
       "77072      Safety 1st Exchangeable Tip 3 in 1 Thermometer   \n",
       "120209  Levana Safe N'See Digital Video Baby Monitor w...   \n",
       "16042         Fisher-Price Ocean Wonders Aquarium Bouncer   \n",
       "\n",
       "                                                   review  rating  \\\n",
       "83234   My Experience: Babykicks Inserts failure vs RA...       5   \n",
       "31741   If I could give this product zero stars I woul...       1   \n",
       "1116    This item is junk.  I originally chose it beca...       1   \n",
       "154878  First, the distance on these are no more than ...       1   \n",
       "149987  It thought this would be great. I did a lot of...       1   \n",
       "75994   I can see why there are so many good reviews o...       2   \n",
       "40079   My wife and I have used this system in two car...       1   \n",
       "172090  I read so many reviews saying the Belkin WiFi ...       2   \n",
       "59546   This is basically an overpriced piece of fabri...       1   \n",
       "9915    I bought this car seat after both seeing  the ...       1   \n",
       "113995  DO NOT BUY THIS BABY MONITOR!I purchased this ...       1   \n",
       "10677   It's 3am in the morning and needless to say, t...       1   \n",
       "81332   I bought this sprayer out of desperation durin...       1   \n",
       "53207   We bought this baby monitor to replace a diffe...       1   \n",
       "94560   Note: we never installed batteries in these un...       1   \n",
       "155287  This is my second video monitoring system, the...       1   \n",
       "48694   I will try to write an objective review of the...       2   \n",
       "77072   I thought it sounded great to have different t...       1   \n",
       "120209  This is the first review I have ever written o...       1   \n",
       "16042   We have not had ANY luck with Fisher-Price pro...       2   \n",
       "\n",
       "                                             review_clean  sentiment  \\\n",
       "83234   My Experience Babykicks Inserts failure vs RAV...          1   \n",
       "31741   If I could give this product zero stars I woul...         -1   \n",
       "1116    This item is junk  I originally chose it becau...         -1   \n",
       "154878  First the distance on these are no more than 7...         -1   \n",
       "149987  It thought this would be great I did a lot of ...         -1   \n",
       "75994   I can see why there are so many good reviews o...         -1   \n",
       "40079   My wife and I have used this system in two car...         -1   \n",
       "172090  I read so many reviews saying the Belkin WiFi ...         -1   \n",
       "59546   This is basically an overpriced piece of fabri...         -1   \n",
       "9915    I bought this car seat after both seeing  the ...         -1   \n",
       "113995  DO NOT BUY THIS BABY MONITORI purchased this m...         -1   \n",
       "10677   Its 3am in the morning and needless to say thi...         -1   \n",
       "81332   I bought this sprayer out of desperation durin...         -1   \n",
       "53207   We bought this baby monitor to replace a diffe...         -1   \n",
       "94560   Note we never installed batteries in these uni...         -1   \n",
       "155287  This is my second video monitoring system the ...         -1   \n",
       "48694   I will try to write an objective review of the...         -1   \n",
       "77072   I thought it sounded great to have different t...         -1   \n",
       "120209  This is the first review I have ever written o...         -1   \n",
       "16042   We have not had ANY luck with FisherPrice prod...         -1   \n",
       "\n",
       "        probabilities  \n",
       "83234    1.656314e-09  \n",
       "31741    1.637796e-09  \n",
       "1116     1.083568e-09  \n",
       "154878   9.092509e-10  \n",
       "149987   7.424565e-10  \n",
       "75994    7.216031e-10  \n",
       "40079    6.570205e-10  \n",
       "172090   6.523675e-10  \n",
       "59546    4.646360e-10  \n",
       "9915     4.132717e-10  \n",
       "113995   1.035454e-10  \n",
       "10677    1.031014e-10  \n",
       "81332    3.967167e-11  \n",
       "53207    3.200936e-11  \n",
       "94560    4.652177e-13  \n",
       "155287   1.758666e-13  \n",
       "48694    1.245939e-13  \n",
       "77072    8.168697e-14  \n",
       "120209   1.845151e-15  \n",
       "16042    8.768872e-16  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort test data according to probability\n",
    "# Quiz Question: Which of the following products are represented in the 20 most positive reviews?\n",
    "\n",
    "test_data_sorted = test_data.sort_values('probabilities', ascending=False)\n",
    "test_data_sorted[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83234</th>\n",
       "      <td>Thirsties Hemp Inserts 2 Pack, Small 6-18 Lbs</td>\n",
       "      <td>My Experience: Babykicks Inserts failure vs RA...</td>\n",
       "      <td>5</td>\n",
       "      <td>My Experience Babykicks Inserts failure vs RAV...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.656314e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31741</th>\n",
       "      <td>Regalo My Cot Portable Bed, Royal Blue</td>\n",
       "      <td>If I could give this product zero stars I woul...</td>\n",
       "      <td>1</td>\n",
       "      <td>If I could give this product zero stars I woul...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.637796e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>Safety 1st Deluxe 4-in-1 Bath Station</td>\n",
       "      <td>This item is junk.  I originally chose it beca...</td>\n",
       "      <td>1</td>\n",
       "      <td>This item is junk  I originally chose it becau...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.083568e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154878</th>\n",
       "      <td>VTech Communications Safe &amp;amp; Sound Digital ...</td>\n",
       "      <td>First, the distance on these are no more than ...</td>\n",
       "      <td>1</td>\n",
       "      <td>First the distance on these are no more than 7...</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.092509e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149987</th>\n",
       "      <td>NUK Cook-n-Blend Baby Food Maker</td>\n",
       "      <td>It thought this would be great. I did a lot of...</td>\n",
       "      <td>1</td>\n",
       "      <td>It thought this would be great I did a lot of ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>7.424565e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75994</th>\n",
       "      <td>Peg-Perego Tatamia High Chair, White Latte</td>\n",
       "      <td>I can see why there are so many good reviews o...</td>\n",
       "      <td>2</td>\n",
       "      <td>I can see why there are so many good reviews o...</td>\n",
       "      <td>-1</td>\n",
       "      <td>7.216031e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40079</th>\n",
       "      <td>Chicco Cortina KeyFit 30 Travel System in Adve...</td>\n",
       "      <td>My wife and I have used this system in two car...</td>\n",
       "      <td>1</td>\n",
       "      <td>My wife and I have used this system in two car...</td>\n",
       "      <td>-1</td>\n",
       "      <td>6.570205e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172090</th>\n",
       "      <td>Belkin WeMo Wi-Fi Baby Monitor for Apple iPhon...</td>\n",
       "      <td>I read so many reviews saying the Belkin WiFi ...</td>\n",
       "      <td>2</td>\n",
       "      <td>I read so many reviews saying the Belkin WiFi ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>6.523675e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59546</th>\n",
       "      <td>Ellaroo Mei Tai Baby Carrier - Hershey</td>\n",
       "      <td>This is basically an overpriced piece of fabri...</td>\n",
       "      <td>1</td>\n",
       "      <td>This is basically an overpriced piece of fabri...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4.646360e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9915</th>\n",
       "      <td>Cosco Alpha Omega Elite Convertible Car Seat</td>\n",
       "      <td>I bought this car seat after both seeing  the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>I bought this car seat after both seeing  the ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4.132717e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113995</th>\n",
       "      <td>Motorola Digital Video Baby Monitor with Room ...</td>\n",
       "      <td>DO NOT BUY THIS BABY MONITOR!I purchased this ...</td>\n",
       "      <td>1</td>\n",
       "      <td>DO NOT BUY THIS BABY MONITORI purchased this m...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.035454e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10677</th>\n",
       "      <td>Philips AVENT Newborn Starter Set</td>\n",
       "      <td>It's 3am in the morning and needless to say, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Its 3am in the morning and needless to say thi...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.031014e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81332</th>\n",
       "      <td>Cloth Diaper Sprayer--styles may vary</td>\n",
       "      <td>I bought this sprayer out of desperation durin...</td>\n",
       "      <td>1</td>\n",
       "      <td>I bought this sprayer out of desperation durin...</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.967167e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53207</th>\n",
       "      <td>Safety 1st High-Def Digital Monitor</td>\n",
       "      <td>We bought this baby monitor to replace a diffe...</td>\n",
       "      <td>1</td>\n",
       "      <td>We bought this baby monitor to replace a diffe...</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.200936e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94560</th>\n",
       "      <td>The First Years True Choice P400 Premium Digit...</td>\n",
       "      <td>Note: we never installed batteries in these un...</td>\n",
       "      <td>1</td>\n",
       "      <td>Note we never installed batteries in these uni...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4.652177e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155287</th>\n",
       "      <td>VTech Communications Safe &amp;amp; Sounds Full Co...</td>\n",
       "      <td>This is my second video monitoring system, the...</td>\n",
       "      <td>1</td>\n",
       "      <td>This is my second video monitoring system the ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.758666e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48694</th>\n",
       "      <td>Adiri BPA Free Natural Nurser Ultimate Bottle ...</td>\n",
       "      <td>I will try to write an objective review of the...</td>\n",
       "      <td>2</td>\n",
       "      <td>I will try to write an objective review of the...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.245939e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77072</th>\n",
       "      <td>Safety 1st Exchangeable Tip 3 in 1 Thermometer</td>\n",
       "      <td>I thought it sounded great to have different t...</td>\n",
       "      <td>1</td>\n",
       "      <td>I thought it sounded great to have different t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>8.168697e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120209</th>\n",
       "      <td>Levana Safe N'See Digital Video Baby Monitor w...</td>\n",
       "      <td>This is the first review I have ever written o...</td>\n",
       "      <td>1</td>\n",
       "      <td>This is the first review I have ever written o...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.845151e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16042</th>\n",
       "      <td>Fisher-Price Ocean Wonders Aquarium Bouncer</td>\n",
       "      <td>We have not had ANY luck with Fisher-Price pro...</td>\n",
       "      <td>2</td>\n",
       "      <td>We have not had ANY luck with FisherPrice prod...</td>\n",
       "      <td>-1</td>\n",
       "      <td>8.768872e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "83234       Thirsties Hemp Inserts 2 Pack, Small 6-18 Lbs   \n",
       "31741              Regalo My Cot Portable Bed, Royal Blue   \n",
       "1116                Safety 1st Deluxe 4-in-1 Bath Station   \n",
       "154878  VTech Communications Safe &amp; Sound Digital ...   \n",
       "149987                   NUK Cook-n-Blend Baby Food Maker   \n",
       "75994          Peg-Perego Tatamia High Chair, White Latte   \n",
       "40079   Chicco Cortina KeyFit 30 Travel System in Adve...   \n",
       "172090  Belkin WeMo Wi-Fi Baby Monitor for Apple iPhon...   \n",
       "59546              Ellaroo Mei Tai Baby Carrier - Hershey   \n",
       "9915         Cosco Alpha Omega Elite Convertible Car Seat   \n",
       "113995  Motorola Digital Video Baby Monitor with Room ...   \n",
       "10677                   Philips AVENT Newborn Starter Set   \n",
       "81332               Cloth Diaper Sprayer--styles may vary   \n",
       "53207                 Safety 1st High-Def Digital Monitor   \n",
       "94560   The First Years True Choice P400 Premium Digit...   \n",
       "155287  VTech Communications Safe &amp; Sounds Full Co...   \n",
       "48694   Adiri BPA Free Natural Nurser Ultimate Bottle ...   \n",
       "77072      Safety 1st Exchangeable Tip 3 in 1 Thermometer   \n",
       "120209  Levana Safe N'See Digital Video Baby Monitor w...   \n",
       "16042         Fisher-Price Ocean Wonders Aquarium Bouncer   \n",
       "\n",
       "                                                   review  rating  \\\n",
       "83234   My Experience: Babykicks Inserts failure vs RA...       5   \n",
       "31741   If I could give this product zero stars I woul...       1   \n",
       "1116    This item is junk.  I originally chose it beca...       1   \n",
       "154878  First, the distance on these are no more than ...       1   \n",
       "149987  It thought this would be great. I did a lot of...       1   \n",
       "75994   I can see why there are so many good reviews o...       2   \n",
       "40079   My wife and I have used this system in two car...       1   \n",
       "172090  I read so many reviews saying the Belkin WiFi ...       2   \n",
       "59546   This is basically an overpriced piece of fabri...       1   \n",
       "9915    I bought this car seat after both seeing  the ...       1   \n",
       "113995  DO NOT BUY THIS BABY MONITOR!I purchased this ...       1   \n",
       "10677   It's 3am in the morning and needless to say, t...       1   \n",
       "81332   I bought this sprayer out of desperation durin...       1   \n",
       "53207   We bought this baby monitor to replace a diffe...       1   \n",
       "94560   Note: we never installed batteries in these un...       1   \n",
       "155287  This is my second video monitoring system, the...       1   \n",
       "48694   I will try to write an objective review of the...       2   \n",
       "77072   I thought it sounded great to have different t...       1   \n",
       "120209  This is the first review I have ever written o...       1   \n",
       "16042   We have not had ANY luck with Fisher-Price pro...       2   \n",
       "\n",
       "                                             review_clean  sentiment  \\\n",
       "83234   My Experience Babykicks Inserts failure vs RAV...          1   \n",
       "31741   If I could give this product zero stars I woul...         -1   \n",
       "1116    This item is junk  I originally chose it becau...         -1   \n",
       "154878  First the distance on these are no more than 7...         -1   \n",
       "149987  It thought this would be great I did a lot of ...         -1   \n",
       "75994   I can see why there are so many good reviews o...         -1   \n",
       "40079   My wife and I have used this system in two car...         -1   \n",
       "172090  I read so many reviews saying the Belkin WiFi ...         -1   \n",
       "59546   This is basically an overpriced piece of fabri...         -1   \n",
       "9915    I bought this car seat after both seeing  the ...         -1   \n",
       "113995  DO NOT BUY THIS BABY MONITORI purchased this m...         -1   \n",
       "10677   Its 3am in the morning and needless to say thi...         -1   \n",
       "81332   I bought this sprayer out of desperation durin...         -1   \n",
       "53207   We bought this baby monitor to replace a diffe...         -1   \n",
       "94560   Note we never installed batteries in these uni...         -1   \n",
       "155287  This is my second video monitoring system the ...         -1   \n",
       "48694   I will try to write an objective review of the...         -1   \n",
       "77072   I thought it sounded great to have different t...         -1   \n",
       "120209  This is the first review I have ever written o...         -1   \n",
       "16042   We have not had ANY luck with FisherPrice prod...         -1   \n",
       "\n",
       "        probabilities  \n",
       "83234    1.656314e-09  \n",
       "31741    1.637796e-09  \n",
       "1116     1.083568e-09  \n",
       "154878   9.092509e-10  \n",
       "149987   7.424565e-10  \n",
       "75994    7.216031e-10  \n",
       "40079    6.570205e-10  \n",
       "172090   6.523675e-10  \n",
       "59546    4.646360e-10  \n",
       "9915     4.132717e-10  \n",
       "113995   1.035454e-10  \n",
       "10677    1.031014e-10  \n",
       "81332    3.967167e-11  \n",
       "53207    3.200936e-11  \n",
       "94560    4.652177e-13  \n",
       "155287   1.758666e-13  \n",
       "48694    1.245939e-13  \n",
       "77072    8.168697e-14  \n",
       "120209   1.845151e-15  \n",
       "16042    8.768872e-16  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quiz Question: Which of the following products are represented in the 20 most negative reviews?\n",
    "test_data_sorted[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27289\n",
      "3789\n",
      "33336\n",
      "accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "#We will now evaluate the accuracy of the trained classifier. Recall that the accuracy is given by\n",
    "\n",
    "#accuracy=# correctly classified examples/# total examples\n",
    "\n",
    "#This can be computed as follows:\n",
    "#•Step 1: Use the sentiment_model to compute class predictions.\n",
    "#•Step 2: Count the number of data points when the predicted class labels match the ground truth labels.\n",
    "#•Step 3: Divide the total number of correct predictions by the total number of data points in the dataset.\n",
    "\n",
    "#Quiz Question: What is the accuracy of the sentiment_model on the test_data? Round your answer to 2 decimal places (e.g. 0.76).\n",
    "true_positives = len(test_data[(test_data['sentiment'] == 1) & (test_data['probabilities'] > 0.5)])\n",
    "print true_positives\n",
    "true_negatives = len(test_data[(test_data['sentiment'] == -1) & (test_data['probabilities'] <= 0.5)])\n",
    "print true_negatives\n",
    "print len(test_data)\n",
    "\n",
    "accuracy = (true_positives + true_negatives) / len(test_data)\n",
    "print \"accuracy: %.2f\" % accuracy\n",
    "#Quiz Question: Does a higher accuracy value on the training_data always imply that the classifier is better?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training the model...\n",
      "finished training the model!\n"
     ]
    }
   ],
   "source": [
    "#Learn another classifier with fewer words\n",
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']\n",
    "\n",
    "vectorizer_word_subset = CountVectorizer(vocabulary=significant_words) # limit to 20 words\n",
    "train_matrix_word_subset = vectorizer_word_subset.fit_transform(train_data['review_clean'])\n",
    "test_matrix_word_subset = vectorizer_word_subset.transform(test_data['review_clean'])\n",
    "\n",
    "print \"training the model...\"\n",
    "simple_model = logistic_regression.fit(train_matrix_word_subset, train_data[\"sentiment\"])\n",
    "print \"finished training the model!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        coef         words\n",
      "0   1.363690          love\n",
      "1   0.944000         great\n",
      "2   1.192538          easy\n",
      "3   0.085513           old\n",
      "4   0.520186        little\n",
      "5   1.509812       perfect\n",
      "6   1.673074         loves\n",
      "7   0.503760          well\n",
      "8   0.190909          able\n",
      "9   0.058855           car\n",
      "10 -1.651576         broke\n",
      "11 -0.209563          less\n",
      "12 -0.511380          even\n",
      "13 -2.033699         waste\n",
      "14 -2.348298  disappointed\n",
      "15 -0.621169          work\n",
      "16 -0.320556       product\n",
      "17 -0.898031         money\n",
      "18 -0.362167         would\n",
      "19 -2.109331        return\n",
      "20\n",
      "20\n",
      "        coef         words\n",
      "6   1.673074         loves\n",
      "5   1.509812       perfect\n",
      "0   1.363690          love\n",
      "2   1.192538          easy\n",
      "1   0.944000         great\n",
      "4   0.520186        little\n",
      "7   0.503760          well\n",
      "8   0.190909          able\n",
      "3   0.085513           old\n",
      "9   0.058855           car\n",
      "11 -0.209563          less\n",
      "16 -0.320556       product\n",
      "18 -0.362167         would\n",
      "12 -0.511380          even\n",
      "15 -0.621169          work\n",
      "17 -0.898031         money\n",
      "10 -1.651576         broke\n",
      "13 -2.033699         waste\n",
      "19 -2.109331        return\n",
      "14 -2.348298  disappointed\n"
     ]
    }
   ],
   "source": [
    "#Let us inspect the weights (coefficients) of the simple_model. First, build a table to store (word, coefficient) pairs.\n",
    "#If you are using SFrame with scikit-learn, you can combine words with coefficients by running\n",
    "\n",
    "simple_model_coef_table = pd.DataFrame({'coef': simple_model.coef_.flatten(), 'words':np.array(significant_words)})\n",
    "print simple_model_coef_table\n",
    "print len(simple_model_coef_table)\n",
    "print len(significant_words)\n",
    "\n",
    "#Sort the data frame by the coefficient value in descending order.\n",
    "\n",
    "simple_model_coef_table_sorted = simple_model_coef_table.sort_values('coef', ascending=False)\n",
    "print simple_model_coef_table_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
